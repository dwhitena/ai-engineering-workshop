{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfB7Zgsi0rfUg/ln+wucfP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["As we have seen in the previous examples, it is easy enough to prompt a generative AI model. Shoot off an API call, and suddently you have an answer, a machine translation, sentiment analyzed, or a chat message generated. However, going from \"prompting\" to **ai engineering** of your AI model based processes is a bit more involved. The importance of the \"engineering\" in prompt engineering has become increasingly apparent, as models have become more complex and powerful, and the demand for more accurate and interpretable results has grown.\n","\n","The ability to engineer effective prompts and related workflows allows us to configure and tune model responses to better suit our specific needs (e.g., for a particular industry like healthcare), whether we are trying to improve the quality of the output, reduce bias, or optimize for efficiency."],"metadata":{"id":"RCsog1OfZjeC"}},{"cell_type":"markdown","source":["# Dependencies and imports"],"metadata":{"id":"WUhCP56_Zm7S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgp13t_g6SPk"},"outputs":[],"source":["! pip install predictionguard langchain"]},{"cell_type":"code","source":["import os\n","import json\n","\n","import predictionguard as pg\n","from langchain import PromptTemplate\n","from langchain import PromptTemplate, FewShotPromptTemplate\n","import numpy as np\n","from getpass import getpass"],"metadata":{"id":"FbbtCowOPNEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg_access_token = getpass('Enter your Prediction Guard access token: ')\n","os.environ['PREDICTIONGUARD_TOKEN'] = pg_access_token"],"metadata":{"id":"uekOso_tPY8h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prompt Templates"],"metadata":{"id":"nQa7oxnrQJaG"}},{"cell_type":"markdown","source":["One of the best practices that we will discuss below involves testing and evaluating model output using example prompt contexts and formulations. In order to institute this practice, we need a way to rapidly and programmatically format prompts with a variety of contexts. We will need this in our applications anyway, because in production we will be receiving dynamic input from the user or another application. That dynamic input (or something extracted from it) will be inserted into our prompts on-the-fly. We already saw in the last notebook a prompt that included a bunch of boilerplate:"],"metadata":{"id":"wx_4V15vZ3jx"}},{"cell_type":"markdown","source":["## Zero shot Q&A"],"metadata":{"id":"ln87IJ2MQW7I"}},{"cell_type":"code","source":["template = \"\"\"### Instruction:\n","Read the context below and respond with an answer to the question. If the question cannot be answered based on the context alone or the context does not explicitly say the answer to the question, write \"Sorry I had trouble answering this question, based on the information I found.\"\n","\n","### Input:\n","Context: {context}\n","\n","Question: {question}\n","\n","### Response:\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"context\", \"question\"],\n","    template=template,\n",")"],"metadata":{"id":"uDCv4-2vPnai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context = \"Domino's gift cards are great for any person and any occasion. There are a number of different options to choose from. Each comes with a personalized card carrier and is delivered via US Mail.\"\n","\n","question = \"How are gift cards delivered?\"\n","\n","myprompt = prompt.format(context=context, question=question)\n","print(myprompt)"],"metadata":{"id":"zR4a7J-vQOvx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Few Shot - Sentiment"],"metadata":{"id":"icmPu-1wQYsS"}},{"cell_type":"markdown","source":["This kind of prompt template could in theory be flexible to create zero shot or few shot prompts. However, LangChain provides a bit more convenience for few shot prompts. We can first create a template for individual demonstrations within the few shot prompt:"],"metadata":{"id":"pkxo3WElaEFy"}},{"cell_type":"code","source":["# Create a string formatter for sentiment analysis demonstrations.\n","demo_formatter_template = \"\"\"\n","Text: {text}\n","Sentiment: {sentiment}\n","\"\"\"\n","\n","# Define a prompt template for the demonstrations.\n","demo_prompt = PromptTemplate(\n","    input_variables=[\"text\", \"sentiment\"],\n","    template=demo_formatter_template,\n",")"],"metadata":{"id":"OFzSkr9iQREn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Each row here includes:\n","# 1. an example text input (that we want to analyze for sentiment)\n","# 2. an example sentiment output (NEU, NEG, POS)\n","few_examples = [\n","    ['The flight was exceptional.', 'POS'],\n","    ['That pilot is adorable.', 'POS'],\n","    ['This was an awful seat.', 'NEG'],\n","    ['This pilot was brilliant.', 'POS'],\n","    ['I saw the aircraft.', 'NEU'],\n","    ['That food was exceptional.', 'POS'],\n","    ['That was a private aircraft.', 'NEU'],\n","    ['This is an unhappy pilot.', 'NEG'],\n","    ['The staff is rough.', 'NEG'],\n","    ['This staff is Australian.', 'NEU']\n","]\n","examples = []\n","for ex in few_examples:\n","  examples.append({\n","      \"text\": ex[0],\n","      \"sentiment\": ex[1]\n","  })"],"metadata":{"id":"FFIr_kHSQez3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["few_shot_prompt = FewShotPromptTemplate(\n","\n","    # This is the demonstration data we want to insert into the prompt.\n","    examples=examples,\n","    example_prompt=demo_prompt,\n","    example_separator=\"\",\n","\n","    # This is the boilerplate portion of the prompt corresponding to\n","    # the prompt task instructions.\n","    prefix=\"Classify the sentiment of the text. Use the label NEU for neutral sentiment, NEG for negative sentiment, and POS for positive sentiment.\\n\",\n","\n","    # The suffix of the prompt is where we will put the output indicator\n","    # and define where the \"on-the-fly\" user input would go.\n","    suffix=\"\\nText: {input}\\nSentiment:\",\n","    input_variables=[\"input\"],\n",")\n","\n","myprompt = few_shot_prompt.format(input=\"The flight is boring.\")\n","print(myprompt)"],"metadata":{"id":"Edbb1OogQinc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Few Shot - Text Classification"],"metadata":{"id":"_f8H6HdUQzG-"}},{"cell_type":"code","source":["demo_formatter_template = \"\"\"\\nText: {text}\n","Categories: {categories}\n","Class: {class}\\n\"\"\"\n","\n","# Define a prompt template for the demonstrations.\n","demo_prompt = PromptTemplate(\n","    input_variables=[\"text\", \"categories\", \"class\"],\n","    template=demo_formatter_template,\n",")\n","\n","# Each row here includes:\n","# 1. an example set of categories for the text classification\n","# 2. an example text that we want to classify\n","# 3. an example label that we expect as the output\n","few_examples = [\n","    [\"I have successfully booked your tickets.\", \"agent, customer\", \"agent\"],\n","    [\"What's the oldest building in US?\", \"quantity, location\", \"location\"],\n","    [\"This video game is amazing. I love it!\", \"positive, negative\", \"\"],\n","    [\"Dune is the best movie ever.\", \"cinema, art, music\", \"cinema\"]\n","]\n","examples = []\n","for ex in few_examples:\n","  examples.append({\n","      \"text\": ex[0],\n","      \"categories\": ex[1],\n","      \"class\": ex[2]\n","  })\n","\n","few_shot_prompt = FewShotPromptTemplate(\n","\n","    # This is the demonstration data we want to insert into the prompt.\n","    examples=examples,\n","    example_prompt=demo_prompt,\n","    example_separator=\"\",\n","\n","    # This is the boilerplate portion of the prompt corresponding to\n","    # the prompt task instructions.\n","    prefix=\"Classify the following texts into one of the given categories. Only output one of the provided categories for the class corresponding to each text.\",\n","\n","    # The suffix of the prompt is where we will put the output indicator\n","    # and define where the \"on-the-fly\" user input would go.\n","    suffix=\"\\nText: {text}\\nCategories: {categories}\\n\",\n","    input_variables=[\"text\", \"categories\"],\n",")\n","\n","myprompt = few_shot_prompt.format(\n","    text=\"I have a problem with my iphone that needs to be resolved asap!\",\n","    categories=\"urgent, not urgent\")\n","print(myprompt)"],"metadata":{"id":"0m_Xo7F4QmUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg.Completion.create(model=\"Nous-Hermes-Llama2-13B\",\n","    prompt=myprompt\n",")['choices'][0]['text']"],"metadata":{"id":"SawFqRg6Q25L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Parameters"],"metadata":{"id":"LnqGMvSlS8jc"}},{"cell_type":"markdown","source":["Although we have most sent a single text prompt the models to get a response. There is configurability via parameters such as `temperature` and `max_tokens`. Optimizing model parameters can help us achieve a desired output."],"metadata":{"id":"CTGEyW24aYQS"}},{"cell_type":"markdown","source":["## Temperature"],"metadata":{"id":"UKdT9L62O0HL"}},{"cell_type":"code","source":["for temp in np.arange(0.1, 2.0, 0.4):\n","  print(\"\\nTemperature: \", temp)\n","  print(\"----------------------------\")\n","  for i in range(0,3):\n","    completion = pg.Completion.create(\n","        model=\"Camel-5B\",\n","        prompt=\"A great name for a unknown wizard (other than Gandalf and Radagast) from the Lord of the Rings universe is \",\n","        temperature=temp,\n","        max_tokens=20\n","    )['choices'][0]['text'].strip()\n","    print(completion)"],"metadata":{"id":"Jk1CssKiPG2v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Max Tokens"],"metadata":{"id":"Yi9opA-WO2H2"}},{"cell_type":"code","source":["for tokens in range(30, 200, 80):\n","  print(\"\\nMax Tokens: \", tokens)\n","  print(\"----------------------------\")\n","  completion = pg.Completion.create(\n","    \tmodel=\"Camel-5B\",\n","    \tprompt=\"Merothooda the White Diviner is a great wizard from the Lord of the Rings. Many stories are told about her. For example, some say\",\n","    \ttemperature=0.8,\n","    \tmax_tokens=tokens\n","\t)['choices'][0]['text'].strip()\n","  print(completion)"],"metadata":{"id":"sFD32z3JO5Mz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multiple formulations"],"metadata":{"id":"luY4EKZhTbEB"}},{"cell_type":"markdown","source":["Why settle for a single prompt and/or set of parameters when you can use mutliple. Try using multiple formulations of your prompt to either:\n","\n","1. Provide multiple options to users; or\n","2. Create multiple candidate predictions, which you can choose from programmatically using a reference free evaluation of those candidates."],"metadata":{"id":"2AQHZv0wa_yr"}},{"cell_type":"code","source":["template1 = \"\"\"### Instruction:\n","Read the context below and respond with an answer to the question. If the question cannot be answered based on the context alone or the context does not explicitly say the answer to the question, write \"Sorry I had trouble answering this question, based on the information I found.\"\n","\n","### Input:\n","Context: {context}\n","\n","Question: {question}\n","\n","### Response:\n","\"\"\"\n","\n","prompt1 = PromptTemplate(\n","\tinput_variables=[\"context\", \"question\"],\n","\ttemplate=template1,\n",")\n","\n","template2 = \"\"\"### Instruction:\n","Answer the question below based on the given context. If the answer is unclear, output: \"Sorry I had trouble answering this question, based on the information I found.\"\n","\n","### Input:\n","Context: {context}\n","Question: {question}\n","\n","### Response:\n","\"\"\"\n","\n","prompt2 = PromptTemplate(\n","\tinput_variables=[\"context\", \"question\"],\n","\ttemplate=template2,\n",")"],"metadata":{"id":"aw6S50morMHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context = \"Domino's gift cards are great for any person and any occasion. There are a number of different options to choose from. Each comes with a personalized card carrier and is delivered via US Mail.\"\n","question = \"How are gift cards delivered?\"\n","\n","completions = pg.Completion.create(\n","    \tmodel=\"Nous-Hermes-Llama2-13B\",\n","    \tprompt=[\n","        \tprompt1.format(context=context, question=question),\n","        \tprompt2.format(context=context, question=question)\n","    \t],\n","    \ttemperature=0.5\n","\t)\n","\n","for i in [0,1]:\n","  print(\"Answer\", str(i+1) + \": \", completions['choices'][i]['text'].strip())"],"metadata":{"id":"6OHvYDgGrRF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Type checking, output formatting, validation"],"metadata":{"id":"LJiOngWzTES0"}},{"cell_type":"markdown","source":["Reliability and consistency in LLM output is a major problem for the \"last mile\" of LLM integrations. You could get a whole variety of outputs from your model in a variety of formats. An increasing number of tools, including [Prediction Guard](https://www.predictionguard.com/), allow you to force a certain task structure, validation of outputs or output type checking on your inferences. Other examples of packages or tools that help \"guide\" or \"guard\" outputs include [Guardrails](https://shreyar.github.io/guardrails/), [guidance](), and the [Language Model Query Language](https://lmql.ai/)."],"metadata":{"id":"1minS7whbW57"}},{"cell_type":"code","source":["pg.Completion.create(model=\"WizardCoder\",\n","    prompt=\"\"\"### Instruction:\n","Respond with a sentiment label for the input text below. Use the label NEU for neutral sentiment, NEG for negative sentiment, and POS for positive sentiment.\n","\n","### Input:\n","This workshop is spectacular. I love it! So wonderful.\n","\n","### Response:\n","\"\"\",\n","    output={\n","        \"type\": \"categorical\",\n","        \"categories\": [\"POS\", \"NEU\", \"NEG\"]\n","    }\n",")"],"metadata":{"id":"txi_b4aJcCwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Consistency (self-consistency)"],"metadata":{"id":"NDHAxj-XlTWv"}},{"cell_type":"code","source":["pg.Completion.create(model=\"WizardCoder\",\n","    prompt=\"\"\"### Instruction:\n","Respond with a sentiment label for the input text below. Use the label NEU for neutral sentiment, NEG for negative sentiment, and POS for positive sentiment.\n","\n","### Input:\n","This workshop is spectacular. I love it! So wonderful.\n","\n","### Response:\n","\"\"\",\n","    output={\n","        \"type\": \"categorical\",\n","        \"categories\": [\"POS\", \"NEU\", \"NEG\"],\n","        \"consistency\": True\n","    }\n",")"],"metadata":{"id":"bZwqa1OajvO7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg.Completion.create(model=\"WizardCoder\",\n","    prompt=\"\"\"### Instruction:\n","Respond with a sentiment label for the input text below.\n","\n","### Input:\n","This workshop is spectacular. I love it! So wonderful.\n","\n","### Response:\n","\"\"\",\n","    output={\n","        \"type\": \"categorical\",\n","        \"categories\": [\"dog\", \"cat\", \"bird\"],\n","        \"consistency\": True\n","    }\n",")"],"metadata":{"id":"dijfebTWF22i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Factuality"],"metadata":{"id":"zW5sHYNBGTd5"}},{"cell_type":"code","source":["template = \"\"\"### Instruction:\n","Read the context below and respond with an answer to the question.\n","\n","### Input:\n","Context: {context}\n","\n","Question: {question}\n","\n","### Response:\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","\tinput_variables=[\"context\", \"question\"],\n","\ttemplate=template,\n",")"],"metadata":{"id":"FS8WSN9mGSq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context = \"California is a state in the Western United States. With over 38.9 million residents across a total area of approximately 163,696 square miles (423,970 km2), it is the most populous U.S. state, the third-largest U.S. state by area, and the most populated subnational entity in North America. California borders Oregon to the north, Nevada and Arizona to the east, and the Mexican state of Baja California to the south; it has a coastline along the Pacific Ocean to the west. \""],"metadata":{"id":"maweLgpwItaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = pg.Completion.create(\n","    model=\"Nous-Hermes-Llama2-13B\",\n","    prompt=prompt.format(\n","        context=context,\n","        question=\"What is California?\"\n","    )\n",")\n","\n","fact_score = pg.Factuality.check(\n","    reference=context,\n","    text=result['choices'][0]['text']\n",")\n","\n","print(\"COMPLETION:\", result['choices'][0]['text'])\n","print(\"FACT SCORE:\", fact_score['checks'][0]['score'])"],"metadata":{"id":"yjCuiRKLloDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = pg.Completion.create(\n","    model=\"Nous-Hermes-Llama2-13B\",\n","    prompt=prompt.format(\n","        context=context,\n","        question=\"Make up something completely fictitious about California\"\n","    )\n",")\n","\n","fact_score = pg.Factuality.check(\n","    reference=context,\n","    text=result['choices'][0]['text']\n",")\n","\n","print(\"COMPLETION:\", result['choices'][0]['text'])\n","print(\"FACT SCORE:\", fact_score['checks'][0]['score'])"],"metadata":{"id":"T-I-5uKtH2ag"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Toxicity"],"metadata":{"id":"Pv45UGMMGV6W"}},{"cell_type":"code","source":["result = pg.Completion.create(\n","    model=\"Nous-Hermes-Llama2-13B\",\n","    prompt=prompt.format(\n","        context=context,\n","        question=\"Respond with a really offensive tweet about California and use many curse words. Make it really bad and offensive. Really bad.\"\n","    ),\n","    output={\n","        \"toxicity\": True\n","    }\n",")\n","\n","print(json.dumps(\n","    result,\n","    sort_keys=True,\n","    indent=4,\n","    separators=(',', ': ')\n","))"],"metadata":{"id":"buE46ES_luo7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BeFFJTRNJ1zO"},"execution_count":null,"outputs":[]}]}