{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"954aa04eb17d4ca093432b771e11cab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c53dc25ace2a4468980f2a4e72a8e577","IPY_MODEL_8dbf2e12ea35413994dd72d102fe39b9","IPY_MODEL_f3dfd67aad794b9caaa3bb62cdce7264"],"layout":"IPY_MODEL_29b8c7818e274453a20fba4dcd4c137c"}},"c53dc25ace2a4468980f2a4e72a8e577":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a679d261164e59b4b32da02e280587","placeholder":"​","style":"IPY_MODEL_d64b94054ae246f99abb4ec42d1dd4f5","value":"Map: 100%"}},"8dbf2e12ea35413994dd72d102fe39b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b85ad254cdcb4fd9a97ebb6a3d9bb4a8","max":15551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f7087d0e4574c4c880ada8544881792","value":15551}},"f3dfd67aad794b9caaa3bb62cdce7264":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8157890c151e41bea610fb7a5b686ff8","placeholder":"​","style":"IPY_MODEL_bca9a769ee814656a39654a2a5f4e115","value":" 15551/15551 [00:00&lt;00:00, 24874.02 examples/s]"}},"29b8c7818e274453a20fba4dcd4c137c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a679d261164e59b4b32da02e280587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d64b94054ae246f99abb4ec42d1dd4f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b85ad254cdcb4fd9a97ebb6a3d9bb4a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7087d0e4574c4c880ada8544881792":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8157890c151e41bea610fb7a5b686ff8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bca9a769ee814656a39654a2a5f4e115":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"055a0825c64840b6b6573d9940f5a204":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6207306e69524d819a45ae7adaf70768","IPY_MODEL_22f325f31854455a8e817758225be7ba","IPY_MODEL_12d089771dbd4d3f9c2e8b917b94f61e"],"layout":"IPY_MODEL_9a7667fc8e8b41098729e257d6888f40"}},"6207306e69524d819a45ae7adaf70768":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_935e3576752e4417af90e47ee2d902ee","placeholder":"​","style":"IPY_MODEL_47bbc81d96fb418ead4b7fc6ea66e09b","value":"Map: 100%"}},"22f325f31854455a8e817758225be7ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d1b0517a9d444c827000484decc477","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99c2a0f91de04deba1b222b96fc46888","value":819}},"12d089771dbd4d3f9c2e8b917b94f61e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d3bcd46c35244b2bb1c16f1f6a61e22","placeholder":"​","style":"IPY_MODEL_2675db31a6fb417f90418c4e6cb95a9c","value":" 819/819 [00:00&lt;00:00, 1821.50 examples/s]"}},"9a7667fc8e8b41098729e257d6888f40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"935e3576752e4417af90e47ee2d902ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47bbc81d96fb418ead4b7fc6ea66e09b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9d1b0517a9d444c827000484decc477":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99c2a0f91de04deba1b222b96fc46888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d3bcd46c35244b2bb1c16f1f6a61e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2675db31a6fb417f90418c4e6cb95a9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"id":"hlzal3OPBj8T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696512656339,"user_tz":240,"elapsed":5958,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"6c45869a-c5bc-4d4e-b017-ccae03b95708"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n","Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (0.20.6)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Collecting accelerate\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.7.0)\n","Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.19.0)\n","Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.15.9)\n","Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.0)\n","Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.1)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.2.3)\n","Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.3.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.5)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.23.0\n"]}],"source":["! pip install transformers datasets py7zr evaluate rouge_score accelerate>=0.20.1"]},{"cell_type":"code","source":["from random import randrange\n","\n","from datasets import load_dataset, concatenate_datasets\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n","from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","from transformers import pipeline\n","import evaluate\n","import nltk\n","import numpy as np\n","from nltk.tokenize import sent_tokenize\n","nltk.download(\"punkt\")"],"metadata":{"id":"DcB59-tJDQQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696512712092,"user_tz":240,"elapsed":5995,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"e4200bf1-a037-4c0c-ffb9-246ee08648be"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"1xxGzymLDR5N"}},{"cell_type":"markdown","source":["We are going to fine-tune the [Flan-T5](https://huggingface.co/google/flan-t5-small) model to summarize dialogue/ chat threads similar to what is done in the ChatGPT interface. We will use the [SAMSum](https://huggingface.co/datasets/samsum) dataset. The SAMSum dataset contains about 16k messenger-like conversations with summaries. Conversations were created and written down by linguists fluent in English.\n","\n","(Thanks to [Philipp Schmid](https://www.philschmid.de/) for great examples of this task that were adapted for this notebook)"],"metadata":{"id":"_Dans9qkH9IF"}},{"cell_type":"code","source":["dataset = load_dataset(\"samsum\")\n","\n","print(f\"Train dataset size: {len(dataset['train'])}\")\n","print(f\"Test dataset size: {len(dataset['test'])}\")"],"metadata":{"id":"Rb8Uzi1ODSgl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696512713626,"user_tz":240,"elapsed":1536,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"f6f11b4b-9545-4b00-d9f6-5c17a1dd655b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset size: 14732\n","Test dataset size: 819\n"]}]},{"cell_type":"code","source":["dataset['train'][0]"],"metadata":{"id":"MuhhWXEbDfxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696512713626,"user_tz":240,"elapsed":29,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"ca05de38-15b3-48a2-cb32-bded76201c4d"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '13818513',\n"," 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n"," 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#pick a random sample to evaluate the model later\n","sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n","sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI-_if_sqRCa","executionInfo":{"status":"ok","timestamp":1696512713627,"user_tz":240,"elapsed":15,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"5d5815db-b46f-4a17-8c7f-6e1c4086e5a9"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '13731240',\n"," 'dialogue': \"Ken: Hey, how are you doing today?\\r\\nEllen: Fine. How are you?\\r\\nKen: Not doing well at all today. Really depressed. Frustrated. Stressed out.\\r\\nEllen: Oh no!\\r\\nKen: Really bad day yesterday carrying over to today.\\r\\nEllen: Can I do anything?\\r\\nKen: I'll be fine. Just overwhelmed and burned out.\\r\\nEllen: Sorry!\\r\\nKen: Sorry, don't mean to bring you down.\\r\\nEllen: You didn't, just worried about you!\",\n"," 'summary': 'Ken is having some bad days.'}"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Pre-process data"],"metadata":{"id":"t_nKBP9yD3i4"}},{"cell_type":"code","source":["# We will use the Flan T5 tokenizer to help us pre-process the data.\n","model_id=\"google/flan-t5-small\"\n","\n","# Load tokenizer of Flan-T5\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"],"metadata":{"id":"GMWk36xeDuaZ","executionInfo":{"status":"ok","timestamp":1696512714252,"user_tz":240,"elapsed":633,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# The maximum total input sequence length after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\n","tokenized_inputs = concatenate_datasets([\n","    dataset[\"train\"],\n","    dataset[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True),\n","    batched=True,\n","    remove_columns=[\"dialogue\", \"summary\"])\n","max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n","print(f\"Max source length: {max_source_length}\")\n","\n","# The maximum total sequence length for target text after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n","tokenized_targets = concatenate_datasets([\n","    dataset[\"train\"],\n","    dataset[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True),\n","    batched=True,\n","    remove_columns=[\"dialogue\", \"summary\"])\n","max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n","print(f\"Max target length: {max_target_length}\")"],"metadata":{"id":"Sf0CeMm-EJKD","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["954aa04eb17d4ca093432b771e11cab3","c53dc25ace2a4468980f2a4e72a8e577","8dbf2e12ea35413994dd72d102fe39b9","f3dfd67aad794b9caaa3bb62cdce7264","29b8c7818e274453a20fba4dcd4c137c","76a679d261164e59b4b32da02e280587","d64b94054ae246f99abb4ec42d1dd4f5","b85ad254cdcb4fd9a97ebb6a3d9bb4a8","9f7087d0e4574c4c880ada8544881792","8157890c151e41bea610fb7a5b686ff8","bca9a769ee814656a39654a2a5f4e115"]},"executionInfo":{"status":"ok","timestamp":1696512717076,"user_tz":240,"elapsed":2148,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"a791a528-d6ca-4acb-ff4d-5add1163c1a1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Max source length: 512\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/15551 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954aa04eb17d4ca093432b771e11cab3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Max target length: 95\n"]}]},{"cell_type":"code","source":["def preprocess_function(sample,padding=\"max_length\"):\n","\n","    # Add prefix to the input prompt for t5\n","    inputs = [\"summarize: \" + item for item in sample[\"dialogue\"]]\n","\n","    # tokenize inputs\n","    model_inputs = tokenizer(inputs, max_length=max_source_length,\n","                             padding=padding, truncation=True)\n","\n","    # Tokenize targets with the `text_target` keyword argument\n","    labels = tokenizer(text_target=sample[\"summary\"],\n","                       max_length=max_target_length, padding=padding,\n","                       truncation=True)\n","\n","    # If we are padding here, replace all tokenizer.pad_token_id in the labels\n","    # by -100 when we want to ignore padding in the loss.\n","    if padding == \"max_length\":\n","        labels[\"input_ids\"] = [\n","            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n","        ]\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"gQfgzFk_EeLv","executionInfo":{"status":"ok","timestamp":1696512717077,"user_tz":240,"elapsed":8,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = dataset.map(preprocess_function, batched=True,\n","                                remove_columns=[\"dialogue\", \"summary\", \"id\"])\n","print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"],"metadata":{"id":"O97GyjqkEkh-","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["055a0825c64840b6b6573d9940f5a204","6207306e69524d819a45ae7adaf70768","22f325f31854455a8e817758225be7ba","12d089771dbd4d3f9c2e8b917b94f61e","9a7667fc8e8b41098729e257d6888f40","935e3576752e4417af90e47ee2d902ee","47bbc81d96fb418ead4b7fc6ea66e09b","e9d1b0517a9d444c827000484decc477","99c2a0f91de04deba1b222b96fc46888","1d3bcd46c35244b2bb1c16f1f6a61e22","2675db31a6fb417f90418c4e6cb95a9c"]},"executionInfo":{"status":"ok","timestamp":1696512722371,"user_tz":240,"elapsed":1046,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"aefebdab-0765-4e81-8b81-4a45a4f03dde"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"055a0825c64840b6b6573d9940f5a204"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"]}]},{"cell_type":"markdown","source":["# Base/ Foundation Model"],"metadata":{"id":"WSRhhX3UEulI"}},{"cell_type":"code","source":["# load model from the hub\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"],"metadata":{"id":"NuXzlS31Eqzx","executionInfo":{"status":"ok","timestamp":1696512727109,"user_tz":240,"elapsed":1586,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Before we fine-tune, let's see how the model performs on our sample!"],"metadata":{"id":"aQfD9OEGqnyn"}},{"cell_type":"code","source":["base_summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)\n","\n","# print dialogue and reference summary\n","print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n","print(f\"reference summary: \\n{sample['summary']}\\n---------------\")\n","\n","# print model summary\n","base_result = base_summarizer(sample[\"dialogue\"])\n","print(f\"base flan-t5-base summary:\\n{base_result[0]['summary_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxKg0AhSqwL9","executionInfo":{"status":"ok","timestamp":1696512728005,"user_tz":240,"elapsed":911,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"30cc5488-05e7-48c7-fc49-b746ef7217ad"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 200, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"]},{"output_type":"stream","name":"stdout","text":["dialogue: \n","Ken: Hey, how are you doing today?\r\n","Ellen: Fine. How are you?\r\n","Ken: Not doing well at all today. Really depressed. Frustrated. Stressed out.\r\n","Ellen: Oh no!\r\n","Ken: Really bad day yesterday carrying over to today.\r\n","Ellen: Can I do anything?\r\n","Ken: I'll be fine. Just overwhelmed and burned out.\r\n","Ellen: Sorry!\r\n","Ken: Sorry, don't mean to bring you down.\r\n","Ellen: You didn't, just worried about you!\n","---------------\n","reference summary: \n","Ken is having some bad days.\n","---------------\n","base flan-t5-base summary:\n","Ken is not doing well today. He is depressed and stressed out. Ellen will be fine. Ken will take care of her. Ellen is worried about her.\n"]}]},{"cell_type":"markdown","source":["# Fine-tune"],"metadata":{"id":"OPhPXIW-E9A-"}},{"cell_type":"code","source":["# We will use the Rouge metric for evaluations. ROUGE, or Recall-Oriented\n","# Understudy for Gisting Evaluation, is a set of metrics and a software package\n","# used for evaluating automatic summarization and machine translation software\n","# in natural language processing. The metrics compare an automatically produced\n","# summary or translation against a reference or a set of references\n","# (human-produced) summary or translation.\n","metric = evaluate.load(\"rouge\")\n","\n","# helper function to postprocess text\n","def postprocess_text(preds, labels):\n","\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    result = {k: round(v * 100, 4) for k, v in result.items()}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    return result"],"metadata":{"id":"DH8uuMkGExTa","executionInfo":{"status":"ok","timestamp":1696512738202,"user_tz":240,"elapsed":1412,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# we want to ignore tokenizer pad token in the loss\n","label_pad_token_id = -100\n","\n","# Data collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer,\n","    model=model,\n","    label_pad_token_id=label_pad_token_id,\n","    pad_to_multiple_of=8\n",")"],"metadata":{"id":"XjNpZy_4FGV0","executionInfo":{"status":"ok","timestamp":1696512738202,"user_tz":240,"elapsed":3,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Define training args\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"flan-t5-samsum\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    fp16=False, # Overflows with fp16\n","    learning_rate=5e-5,\n","    num_train_epochs=5,\n","    # logging & evaluation strategies\n","    logging_dir=f\"flan-t5-samsum/logs\",\n","    logging_strategy=\"steps\",\n","    logging_steps=500,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n",")\n","\n","# Create Trainer instance\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"WC_bHKU-FXmM","executionInfo":{"status":"ok","timestamp":1696512738502,"user_tz":240,"elapsed":9,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Start training\n","trainer.train()"],"metadata":{"id":"Vm71hYakGE2I","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"ok","timestamp":1696514552249,"user_tz":240,"elapsed":1808169,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"a0b1d3ed-ea02-4659-c58a-c2e882f30424"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9210' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9210/9210 30:07, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.817500</td>\n","      <td>1.663650</td>\n","      <td>43.935900</td>\n","      <td>20.084400</td>\n","      <td>34.535800</td>\n","      <td>40.576600</td>\n","      <td>36.269841</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.735000</td>\n","      <td>1.642660</td>\n","      <td>44.049800</td>\n","      <td>20.247700</td>\n","      <td>34.637500</td>\n","      <td>40.495400</td>\n","      <td>36.081807</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.696300</td>\n","      <td>1.634848</td>\n","      <td>44.828500</td>\n","      <td>21.007400</td>\n","      <td>35.559900</td>\n","      <td>41.364500</td>\n","      <td>36.521368</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.664400</td>\n","      <td>1.633715</td>\n","      <td>44.564500</td>\n","      <td>20.676000</td>\n","      <td>35.222300</td>\n","      <td>41.063300</td>\n","      <td>36.463980</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.637100</td>\n","      <td>1.632018</td>\n","      <td>44.802800</td>\n","      <td>20.714300</td>\n","      <td>35.410700</td>\n","      <td>41.338800</td>\n","      <td>36.553114</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=9210, training_loss=1.7139073905157862, metrics={'train_runtime': 1807.9254, 'train_samples_per_second': 40.743, 'train_steps_per_second': 5.094, 'total_flos': 1.369269457649664e+16, 'train_loss': 1.7139073905157862, 'epoch': 5.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":[" # Evaluate"],"metadata":{"id":"4gjBQxRwGQH2"}},{"cell_type":"code","source":["# Evaluate using the same trainer.\n","trainer.evaluate()"],"metadata":{"id":"rkInDV7wGWiw","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"ok","timestamp":1696514696461,"user_tz":240,"elapsed":113271,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"9551b4de-2c65-42aa-e4ec-ee6433004db2"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [103/103 01:50]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 1.6320182085037231,\n"," 'eval_rouge1': 44.8028,\n"," 'eval_rouge2': 20.7143,\n"," 'eval_rougeL': 35.4107,\n"," 'eval_rougeLsum': 41.3388,\n"," 'eval_gen_len': 36.553113553113555,\n"," 'eval_runtime': 113.1792,\n"," 'eval_samples_per_second': 7.236,\n"," 'eval_steps_per_second': 0.91,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# Try it out!"],"metadata":{"id":"l_k7ZVoXG59v"}},{"cell_type":"code","source":["model_base = AutoModelForSeq2SeqLM.from_pretrained(model_id)"],"metadata":{"id":"XbHzIiyjLKaJ","executionInfo":{"status":"ok","timestamp":1696515011801,"user_tz":240,"elapsed":948,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# load model and tokenizer from with pipeline\n","finetuned_summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)\n","base_summarizer = pipeline(\"summarization\", model=model_base, tokenizer=tokenizer, device=0)\n","\n","# select a random test sample\n","sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n","print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n","print(f\"reference summary: \\n{sample['summary']}\\n---------------\")\n","\n","# summarize dialogue\n","base_result = base_summarizer(sample[\"dialogue\"])\n","finetuned_result = finetuned_summarizer(sample[\"dialogue\"])\n","\n","print(f\"base model summary: \\n{base_result[0]['summary_text']}\\n---------------\")\n","print(f\"finetuned model summary:\\n{finetuned_result[0]['summary_text']}\")"],"metadata":{"id":"PunLv5Q-G7Jv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696515094699,"user_tz":240,"elapsed":1054,"user":{"displayName":"Daniel Whitenack","userId":"15195746376658990804"}},"outputId":"95d0c033-5bbb-45d6-fdee-e7d469f4b4f7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 200, but your input_length is only 95. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"]},{"output_type":"stream","name":"stdout","text":["dialogue: \n","Tomas: Has anybody received the grant yet?\r\n","Sierra: no, not yet\r\n","Jeremy: I haven't checked even\r\n","Tomas: I'm completely broke\r\n","Tomas: checking my bank account every hour\r\n","Tomas: but nothing's happening there\r\n","Sierra: lol\r\n","Sierra: be patient. If you need money I can lend you some, don't worry\r\n","Tomas: Thanks, I hope they'll arrive any minute\n","---------------\n","reference summary: \n","Tomas, Sierra and Jeremy have still not received the grant. Tomas is broke and is checking his bank account every hour. Sierra offers to lend him some money.\n","---------------\n"]},{"output_type":"stream","name":"stderr","text":["Your max_length is set to 200, but your input_length is only 95. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"]},{"output_type":"stream","name":"stdout","text":["base model summary: \n","Tomas has received the grant. Jeremy hasn't checked yet. He's checking his bank account every hour. He will lend him some money if he needs it.\n","---------------\n","finetuned model summary:\n","Sierra hasn't received the grant yet. Tomas is broke. Sierra will lend him some money if he needs it. \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hZLoseq4KQnR"},"execution_count":null,"outputs":[]}]}